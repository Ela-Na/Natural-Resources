{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "879f4438-b0ea-4e9b-ab5a-2cd68c7b3eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip -q install rasterio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a3db457-2377-42ad-8dbd-7c253bc08cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fbaf0ac-aaa5-4ccd-ab66-bc3da9c7099d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import rasterio as rs\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "from google.colab import drive\n",
    "from IPython.display import clear_output\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score, confusion_matrix\n",
    "from sklearn.utils.class_weight import compute_class_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a608311c-aff3-4eec-b528-4dda63643014",
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)\n",
    "tf.random.set_seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfa555bd-77e1-489f-92a9-fb68e602a89e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile constants.py\n",
    "# Data\n",
    "BATCH_SIZE = 32\n",
    "BUFFER_SIZE = 1000\n",
    "DATASET_DIR = \"/content/land-cover-dataset\"\n",
    "DRIVE_DIR = \"/content/drive/MyDrive/Colab\\ Notebooks/land-cover-classification\"\n",
    "RECORDS_ZIP = \"land-cover-classification-records.zip\"\n",
    "TENSORFLOW_DATASETS = \"/root/tensorflow_datasets\"\n",
    "\n",
    "## Dataset Builder\n",
    "BANDS = [ \"B01\", \"B02\", \"B03\", \"B04\", \"B05\", \"B06\", \"B07\", \"B08\", \"B09\", \"B11\", \"B12\", \"B8A\" ]\n",
    "NUM_EXAMPLES = 22686  # Manually observed by taking the len of LandCoverClassification.patches\n",
    "NUM_LABELS = 18\n",
    "PATCH_SIZE = 128\n",
    "BANDS_SHAPE = (PATCH_SIZE, PATCH_SIZE, len(BANDS))\n",
    "LABELS_SHAPE = (PATCH_SIZE, PATCH_SIZE, 1)\n",
    "STRIDE = PATCH_SIZE // 2\n",
    "\n",
    "## Exploration\n",
    "CLC_TIF = \"/content/CAN_LC_2015_CAL.tif\"\n",
    "\n",
    "# Model\n",
    "EPOCHS = 50\n",
    "FILTERS = 64\n",
    "LEARNING_RATE = 1e-4\n",
    "STEPS_PER_EPOCH = (0.8 * NUM_EXAMPLES) // BATCH_SIZE\n",
    "VALIDATION_SPLITS = 5\n",
    "VALIDATION_STEPS = (0.2 * NUM_EXAMPLES) // BATCH_SIZE // VALIDATION_SPLITS\n",
    "\n",
    "# Testing\n",
    "TEST_DATASET = \"/content/demo_site.csv\"\n",
    "TEST_SHAPE = (2500, 2100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50def796-6041-47d2-9ea3-bd33ed391e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "from constants import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da81b99e-5008-4f62-a99d-4363d9c252a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "drive.mount(\"/content/drive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7883fcde-b122-41bc-b130-993bafb9beab",
   "metadata": {},
   "outputs": [],
   "source": [
    "drive.flush_and_unmount()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "744b137b-e4be-4966-a824-b58c22c73346",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27780bde-d68b-431c-afbe-d90fb2b729de",
   "metadata": {},
   "source": [
    "This will download the data directory to `/content/dataset`. The images were manually downloaded from Sentinel Hub using the EO browser. The dataset folder is organized as follows:\n",
    "\n",
    "```\n",
    "dataset/\n",
    "    Site1/\n",
    "        B01.tiff\n",
    "        ...\n",
    "        Labels.tiff\n",
    "    Site2/\n",
    "        ...\n",
    "    ...\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7ab745d-c14b-484b-8358-b56d67e55622",
   "metadata": {},
   "outputs": [],
   "source": [
    "!gdown 1emQ6BUD8pi7ZcRKvb0nFR_ynO6IaSXaY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b64c9399-6b50-47c2-a2fe-99cfb867b1a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "!unzip -qq land-cover-dataset.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e3b5918-593b-4d7e-bbb5-33fe797cb3a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p $TENSORFLOW_DATASETS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa2ce717-ba93-424e-a280-0caab36e7161",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp -r $DRIVE_DIR/$RECORDS_ZIP $TENSORFLOW_DATASETS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee813d73-ccf7-4517-8f8d-4c73fa4e6d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pushd $TENSORFLOW_DATASETS\n",
    "!unzip $RECORDS_ZIP\n",
    "%popd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2601ea3e-585d-4c82-a377-8613fb309fb4",
   "metadata": {},
   "source": [
    "## Dataset Builder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b669a29-fd84-43c3-905e-ab3c5d390fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile land_cover_classification.py\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import rasterio as rs\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import textwrap\n",
    "\n",
    "from constants import *\n",
    "\n",
    "\n",
    "class LandCoverClassification(tfds.core.GeneratorBasedBuilder):\n",
    "    VERSION = tfds.core.Version(\"0.0.1\")\n",
    "\n",
    "    MANUAL_DOWNLOAD_INSTRUCTIONS = textwrap.dedent(f\"\"\"\n",
    "    The land-cover-dataset.zip should be downloaded and extracted to the manual_dir\n",
    "    \"\"\")\n",
    "\n",
    "    def _info(self):\n",
    "        return tfds.core.DatasetInfo(\n",
    "            builder=self,\n",
    "            features=tfds.features.FeaturesDict(\n",
    "                dict(\n",
    "                    bands=tfds.features.Tensor(shape=BANDS_SHAPE, dtype=tf.float32),\n",
    "                    labels=tfds.features.Tensor(shape=LABELS_SHAPE, dtype=tf.uint8),\n",
    "                )\n",
    "            ),\n",
    "            supervised_keys=(\"bands\", \"labels\"),\n",
    "        )\n",
    "    \n",
    "    @classmethod\n",
    "    def _get_bands_generator(cls, site_path):\n",
    "        for band in BANDS:\n",
    "            band_path = site_path / f\"{band}.tiff\"\n",
    "            with rs.open(band_path) as tiff:\n",
    "                yield tiff.read(1)  # The TIFF shape should be 1 x R X C\n",
    "\n",
    "    def _generate_examples(self, manual_dir):\n",
    "        return self.patches(dataset_dir=manual_dir)\n",
    "\n",
    "    def _get_labels(site_path):\n",
    "        labels_path = site_path / \"Labels.tiff\"\n",
    "        with rs.open(labels_path) as tiff:\n",
    "            return tiff.read(1)  # The TIFF shape should be 1 x R X C\n",
    "\n",
    "    def mode(labels):\n",
    "        values, counts = np.unique(labels.reshape(-1), return_counts=True)\n",
    "        argmax = counts.argmax()\n",
    "        return values[argmax]\n",
    "\n",
    "    def _split_generators(self, dl_manager):\n",
    "        return [\n",
    "            tfds.core.SplitGenerator(\n",
    "                name=tfds.Split.TRAIN, gen_kwargs={ \"manual_dir\": dl_manager.manual_dir })]\n",
    "\n",
    "    @classmethod\n",
    "    def patches(cls, dataset_dir, patch_size=PATCH_SIZE, stride=STRIDE):\n",
    "        dataset_path = Path(dataset_dir)\n",
    "        for site_path in dataset_path.iterdir():\n",
    "            bands = [band for band in cls._get_bands_generator(site_path)]\n",
    "            bands = np.dstack(bands)\n",
    "            labels = cls._get_labels(site_path) \n",
    "            labels[labels > NUM_LABELS] = cls.mode(labels)  # Clamped labels from qGIS have values of 255\n",
    "            labels -= 1  # Shift 1-19 to 0-18\n",
    "\n",
    "            if bands.shape[:2] != labels.shape[:2]:\n",
    "                raise ValueError(\n",
    "                    f\"Bands shape {bands.shape[:2]} differs from labels shape {labels.shape[:2]}\")\n",
    "\n",
    "            rows, cols = labels.shape\n",
    "            r_start = 0\n",
    "            while r_start + patch_size <= rows:\n",
    "                c_start = 0\n",
    "                while c_start + patch_size <= cols:\n",
    "                    r_end, c_end = r_start + patch_size, c_start + patch_size\n",
    "                    yield f\"{site_path.name}_{r_start}_{c_start}\", dict(\n",
    "                        bands=bands[r_start:r_end, c_start:c_end, :], \n",
    "                        labels=labels[r_start:r_end, c_start:c_end, np.newaxis]\n",
    "                    )\n",
    "                    c_start += stride\n",
    "                r_start += stride"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3241f0a3-5fad-4b6e-9e12-ae66421db731",
   "metadata": {},
   "outputs": [],
   "source": [
    "from land_cover_classification import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d660cab-08dc-4220-a6aa-f813abe7160c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_builder = LandCoverClassification()\n",
    "dataset_builder.download_and_prepare(\n",
    "    download_dir=None,\n",
    "    download_config=tfds.download.DownloadConfig(manual_dir=DATASET_DIR)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f55af49d-086b-48ff-85b1-2c9193efcb7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pushd $TENSORFLOW_DATASETS\n",
    "!zip -q -r $RECORDS_ZIP land_cover_classification/0.0.1\n",
    "%popd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3bb93b7-8594-4047-9377-26e463bdbdcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp $TENSORFLOW_DATASETS/$RECORDS_ZIP $DRIVE_DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "366da86a-f551-4eaa-8043-57ebb0fcb0fb",
   "metadata": {},
   "source": [
    "## Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f45fada-354d-4eb9-94f1-eead29231c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = dataset_builder.as_dataset(split=\"train\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bf58acd-56b3-466d-a978-f7c699910c0c",
   "metadata": {},
   "source": [
    "### Ground truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa892789-35ac-41f1-a7ee-e1d09f8b4f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!gdown 1db6viZTDWvQwNI2ZGV-K_rMzTXplruyA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9f4841a-2aa2-4cc7-9d49-b1e01d9dae82",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_counts = np.zeros((20,))\n",
    "with rs.open(CLC_TIF) as src:\n",
    "    for ji, window in src.block_windows(1):\n",
    "        r = src.read(1, window=window)\n",
    "        unique, counts = np.unique(r, return_counts=True)\n",
    "        label_counts[unique] += counts\n",
    "label_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46457bbe-669f-4074-83d9-87a4540136af",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(1, 20)\n",
    "plt.hist(x, bins=x, weights=label_counts[1:])\n",
    "plt.xticks(x)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63654a17-9fbb-4b31-95b6-4bbb07031a13",
   "metadata": {},
   "source": [
    "### Distribution of labels in dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64f2131c-d307-4cd0-8321-dcde7d42c969",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_counts = np.zeros((19,))\n",
    "for example in ds:\n",
    "    unique, counts = np.unique(example[\"labels\"], return_counts=True)\n",
    "    label_counts[unique] += counts\n",
    "label_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0b14179-8b55-48d3-ad3f-17b5194d74f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(1, 20)\n",
    "plt.hist(x, bins=x, weights=label_counts)\n",
    "plt.xticks(x)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93ac0c45-ee07-4ffd-b31e-4c5bcc42f2b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(1, 20)\n",
    "plt.hist(x, bins=x, weights=label_counts)\n",
    "plt.xticks(x)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eff0237f-d40b-42db-9182-c438cbdf80c6",
   "metadata": {},
   "source": [
    "## Sample weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad812df1-a97e-465d-9f93-702d55bfe198",
   "metadata": {},
   "source": [
    "The label counts are found from the dataset label counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "074e2ea0-e38c-4b5e-9ab9-40d3b2260f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_counts = np.array([\n",
    "    9.9853494e+07, 1.5254600e+05, 0.0000000e+00, 0.0000000e+00,\n",
    "    3.0987457e+07, 4.9994951e+07, 0.0000000e+00, 1.9119345e+07,\n",
    "    0.0000000e+00, 3.0745477e+07, 9.5980000e+03, 3.9473600e+05,\n",
    "    5.5446400e+05, 1.2379118e+07, 8.9333039e+07, 1.0883219e+07,\n",
    "    6.0164860e+06, 2.1263494e+07, 0.0000000e+00\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0349f90b-ac94-4ed3-8427-7e09bb6d0722",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = np.sum(label_counts)\n",
    "class_weights = np.repeat([n_samples], NUM_LABELS + 1)\n",
    "class_weights /= (label_counts + 1)\n",
    "class_weights /= NUM_LABELS\n",
    "class_weights[[2, 3, 6]] = 0\n",
    "class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11955f1b-8a18-49b1-b7a5-468d3c4e099c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights = [\n",
    "    2.06795980e-01, 1.35363536e+02, 0.00000000e+00, 0.00000000e+00,\n",
    "    6.66376097e-01, 4.13027726e-01, 0.00000000e+00, 1.08002132e+00,\n",
    "    2.06493013e+07, 6.71620761e-01, 2.15119297e+03, 5.23115425e+01,\n",
    "    3.72418481e+01, 1.66807519e+00, 2.31149655e-01, 1.89735219e+00,\n",
    "    3.43211933e+00, 9.71115112e-01, 2.06493013e+07\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1070feb1-c9ac-43c7-b9b4-4ed61dddf7c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_sample_weights(bands, labels):\n",
    "    sample_weights = tf.gather(class_weights, indices=tf.cast(labels, tf.int32))\n",
    "    return bands, labels, sample_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a11a9b2-4146-45d5-8849-c4c5fffb48c9",
   "metadata": {},
   "source": [
    "## Augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "073da444-80ca-4131-ba2f-4c44a455be96",
   "metadata": {},
   "source": [
    "The augmentation and batching is taken from [Image segmentation](https://www.tensorflow.org/tutorials/images/segmentation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc178dd4-0315-4d36-8a0c-a8a3d8b22c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Augment(tf.keras.layers.Layer):\n",
    "    def __init__(self, seed=RANDOM_SEED):\n",
    "        super().__init__()\n",
    "        # both use the same seed, so they'll make the same random changes.\n",
    "        self.augment_inputs = tf.keras.layers.RandomFlip(seed=seed)\n",
    "        self.augment_labels = tf.keras.layers.RandomFlip(seed=seed)\n",
    "\n",
    "    def call(self, inputs, labels):\n",
    "        inputs = self.augment_inputs(inputs)\n",
    "        labels = self.augment_labels(labels)\n",
    "        return inputs, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79535f95-8875-4281-a5ca-f98e8c863f8f",
   "metadata": {},
   "source": [
    "## Splits & Batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4426cdc2-e899-42e4-9ca2-864634c7eb2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds, val_ds = dataset_builder.as_dataset(\n",
    "    split=[\"train[:80%]\", \"train[80%:]\"],\n",
    "    shuffle_files=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5ec004e-858a-45b5-9860-96cafe24184a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bands_and_labels(example):\n",
    "    return example[\"bands\"], example[\"labels\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a31e67b-cb68-46dc-ac9d-68a9618f6830",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_batches = (\n",
    "    train_ds\n",
    "    .map(get_bands_and_labels, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    .cache()\n",
    "    .shuffle(BUFFER_SIZE)\n",
    "    .batch(BATCH_SIZE)\n",
    "    .repeat()\n",
    "    .map(Augment())\n",
    "    .map(add_sample_weights, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    .prefetch(buffer_size=tf.data.AUTOTUNE))\n",
    "\n",
    "val_batches = (\n",
    "    val_ds\n",
    "    .map(get_bands_and_labels, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    .batch(BATCH_SIZE))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76c19f49-0bf3-40b9-a77f-dcb6b29b840a",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e33e4b4-1123-47b3-9f95-174fb3394844",
   "metadata": {},
   "source": [
    "## U-Net"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fc01083-4ca4-476f-9737-59a4f29e0db7",
   "metadata": {},
   "source": [
    "The U-Net is adapted from [VidushiBhatia/U-Net-Implementation](https://github.com/VidushiBhatia/U-Net-Implementation/blob/main/U_Net_for_Image_Segmentation_From_Scratch_Using_TensorFlow_v4.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5cdf7f3-aad5-4fc8-a08f-f523f4ea9b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder_block(inputs, filters, dropout_rate=0, include_pooling=True, **convargs):\n",
    "    x = tf.keras.layers.Conv2D(filters, **convargs)(inputs)\n",
    "    x = tf.keras.layers.Conv2D(filters, **convargs)(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    if dropout_rate:     \n",
    "        x = tf.keras.layers.Dropout(dropout_rate)(x)\n",
    "    skip = x\n",
    "    if include_pooling:\n",
    "        x = tf.keras.layers.MaxPooling2D(pool_size=2)(x)\n",
    "    return x, skip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa4a8db8-c304-45a5-8d21-7bf8c93ef760",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder_block(inputs, skip, filters, dropout_rate=0, pool_size=(2, 2), **convargs):\n",
    "    x = tf.keras.layers.Conv2DTranspose(\n",
    "        filters, kernel_size=3, strides=2, padding=\"same\")(inputs)\n",
    "    x = tf.keras.layers.concatenate([x, skip], axis=3)\n",
    "    x = tf.keras.layers.Conv2D(filters, **convargs)(x)\n",
    "    return tf.keras.layers.Conv2D(filters, **convargs)(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7db3f56-8f5d-41d3-b9d8-ce6f2a582656",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unet(input_shape, n_classes, dilation_rate=1, filters=FILTERS, learning_rate=LEARNING_RATE):\n",
    "    inputs = tf.keras.Input(shape=input_shape)\n",
    "    convargs = dict(\n",
    "        kernel_size=3, \n",
    "        padding=\"same\", \n",
    "        dilation_rate=dilation_rate, \n",
    "        activation=\"relu\", \n",
    "        kernel_initializer=\"glorot_uniform\"\n",
    "    )\n",
    "\n",
    "    # encoder\n",
    "    enc1, skip1 = encoder_block(inputs, filters, **convargs)\n",
    "    enc2, skip2 = encoder_block(enc1, filters * 2, **convargs)\n",
    "    enc3, skip3 = encoder_block(enc2, filters * 4, **convargs)\n",
    "    enc4, skip4 = encoder_block(enc3, filters * 8, dropout_rate=0.3, **convargs)\n",
    "    enc5, _ = encoder_block(enc4, filters * 16, dropout_rate=0.3, include_pooling=False, **convargs)\n",
    "\n",
    "    # decoder\n",
    "    dec6 = decoder_block(enc5, skip4, filters * 8, **convargs)\n",
    "    dec7 = decoder_block(dec6, skip3, filters * 4, **convargs)\n",
    "    dec8 = decoder_block(dec7, skip2, filters * 2, **convargs)\n",
    "    dec9 = decoder_block(dec8, skip1, filters, **convargs)\n",
    "\n",
    "    conv10 = tf.keras.layers.Conv2D(filters, **convargs)(dec9)\n",
    "    outputs = tf.keras.layers.Conv2D(n_classes, 1, padding=\"same\")(conv10)\n",
    "\n",
    "    model = tf.keras.Model(inputs=inputs, outputs=outputs, name=\"unet\")\n",
    "    model.compile(\n",
    "        optimizer=tf.optimizers.Adam(learning_rate=LEARNING_RATE),\n",
    "        loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "        metrics=[\"accuracy\"])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2473d3d-67f7-4282-adb1-ac5a5ec42f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = unet(BANDS_SHAPE, n_classes=NUM_LABELS, filters=FILTERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ee3e780-d3ed-4d5d-a9fb-11f72778f8b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.utils.plot_model(model, show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fcaff93-5327-45d4-a134-83b0d65c07bd",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02ce38ef-5704-4075-bded-f2abcaae7fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_SAVE = f\"{model.name}.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24e3d594-a775-46ad-b21e-5a36d56e4978",
   "metadata": {},
   "outputs": [],
   "source": [
    "for example in val_ds.take(1):\n",
    "    example_bands, example_labels = example[\"bands\"], example[\"labels\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ffdd93b-b05a-4030-b884-7e2cc40c5178",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DisplayPredictionCallback(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, example_bands, example_labels):\n",
    "        self.example_bands = example_bands\n",
    "        self.example_labels = example_labels\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        clear_output(wait=True)\n",
    "        x = self.example_bands[tf.newaxis, ...]\n",
    "        preds = model.predict(x)\n",
    "        labels = tf.math.argmax(preds, axis=-1)\n",
    "        labels = labels[..., tf.newaxis]\n",
    "\n",
    "        _, (ax1, ax2) = plt.subplots(1, 2, figsize=(8, 8))\n",
    "        ax1.set_title(\"True Labels\")\n",
    "        ax1.imshow(tf.keras.utils.array_to_img(self.example_labels))\n",
    "        ax1.axis(\"off\")\n",
    "        ax2.set_title(\"Predicted Labels\")\n",
    "        ax2.imshow(tf.keras.utils.array_to_img(labels[0]))\n",
    "        ax2.axis(\"off\")\n",
    "        plt.show()\n",
    "\n",
    "        print(f\"\\nPrediction after epoch {epoch + 1}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12a1aa2d-b709-4953-ba99-cdf4ab04574d",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    train_batches,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=val_batches,\n",
    "    steps_per_epoch=STEPS_PER_EPOCH,\n",
    "    validation_steps=VALIDATION_STEPS,\n",
    "    callbacks=[\n",
    "        DisplayPredictionCallback(example_bands, example_labels),\n",
    "        tf.keras.callbacks.ModelCheckpoint(MODEL_SAVE, save_best_only=True)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06090e44-eca5-4178-a76c-bf044ef6c812",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = history.history[\"loss\"]\n",
    "val_loss = history.history[\"val_loss\"]\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(history.epoch, loss, \"r\", label=\"Training loss\")\n",
    "plt.plot(history.epoch, val_loss, \"bo\", label=\"Validation loss\")\n",
    "plt.title(\"Training and Validation Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss Value\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23c96c00-2a15-4b95-a150-65cb9edb2c43",
   "metadata": {},
   "source": [
    "# Loading model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4653c530-9dff-4259-bfb4-38538e0b2207",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp $MODEL_SAVE $DRIVE_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "150278ac-aa82-43ef-bd95-eecd62785f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!gdown 1ARjOomw3Ztfpu09ApToTTUyGxmjO9UL_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3975c157-42dc-4e12-843b-42a4d944a17d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model(\"unet.h5\")  # Note that the model name is hardcoded!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96adb738-dbaa-441a-baf0-ca2f49854fd9",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a88b2c4-8d88-43ee-9a35-7a9f49d20f9c",
   "metadata": {},
   "source": [
    "## Download"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f809a2d-b06b-4044-a482-f7bf06547904",
   "metadata": {},
   "source": [
    "The testing data is take from the [project_example.ipynb](https://colab.research.google.com/drive/1Odk9BFvriINUrD8Lma-fQ8up5pKih3ec?usp=sharing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8de3c54c-e445-47f9-b0de-7bcf386b218f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!gdown 12NT2Ejt7DsujvyAmmlB8VrsDY7irtFEh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "923cc853-6ad5-4173-8bbc-4beca9ee10e3",
   "metadata": {},
   "source": [
    "## DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89a8b28e-9160-4f10-b85e-e5c14a1f72c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv(TEST_DATASET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "771fda88-6c9a-4889-8462-9011d9080979",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_series = test_df[\"land_cover\"]\n",
    "labels_series = labels_series.astype(\"uint8\")\n",
    "labels_series -= 1  # shift\n",
    "bands_df = test_df.drop(columns=\"land_cover\", axis=1)\n",
    "bands_df = bands_df.astype(\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4def63b0-0a93-486b-8971-54c5b8011abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "bands_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fd41036-1a5e-47f2-a3bc-c85dcabb5893",
   "metadata": {},
   "source": [
    "## Distribution of test labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43d9d2c2-62ed-465b-92d1-b6b3d2ad072d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x=labels_series)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba34c1d4-0d77-4a5f-9ee1-4177178d9073",
   "metadata": {},
   "source": [
    "## Reshape the tabular data into an image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "740d55fa-995f-4f2d-98f9-eed919e011a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "im_bands = (bands_df[band].to_numpy().reshape(TEST_SHAPE) for band in BANDS)\n",
    "im_bands = (im_band for im_band in im_bands)\n",
    "im_bands = np.dstack(list(im_bands))\n",
    "im_labels = labels_series.to_numpy().reshape(TEST_SHAPE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98499ba6-e70b-4d71-b953-74ecb83891c6",
   "metadata": {},
   "source": [
    "## Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9345bb59-e22d-4516-8eca-ac46ee782de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_predictions(\n",
    "    model, \n",
    "    bands,\n",
    "    n_classes=NUM_LABELS, \n",
    "    input_shape=TEST_SHAPE, \n",
    "    patch_size=PATCH_SIZE\n",
    "):\n",
    "    labels = np.zeros(TEST_SHAPE)\n",
    "    rows, cols = input_shape\n",
    "    for r_start in range(0, rows // patch_size * patch_size, patch_size):\n",
    "        for c_start in range(0, cols // patch_size * patch_size, patch_size):\n",
    "            r_end, c_end = r_start + patch_size, c_start + patch_size\n",
    "            x = bands[r_start:r_end, c_start:c_end, :]\n",
    "            x = x[np.newaxis, :]\n",
    "            preds = model.predict(x)\n",
    "            argmax = np.argmax(preds[0], axis=-1)\n",
    "            labels[r_start:r_end, c_start:c_end] = argmax\n",
    "    \n",
    "    # row edge\n",
    "    c_start = cols - patch_size\n",
    "    for r_start in range(0, rows // patch_size * patch_size, patch_size):\n",
    "        r_end = r_start + patch_size\n",
    "        x = bands[r_start:r_end, c_start:]\n",
    "        x = x[np.newaxis, :]\n",
    "        preds = model.predict(x)\n",
    "        argmax = np.argmax(preds[0], axis=-1)\n",
    "        labels[r_start:r_end, c_start:] = argmax\n",
    "    \n",
    "    # cols edge\n",
    "    r_start = rows - patch_size\n",
    "    for c_start in range(0, cols // patch_size * patch_size, patch_size):\n",
    "        c_end = c_start + patch_size\n",
    "        x = bands[r_start:, c_start:c_end]\n",
    "        x = x[np.newaxis, :]\n",
    "        preds = model.predict(x)\n",
    "        argmax = np.argmax(preds[0], axis=-1)\n",
    "        labels[r_start:, c_start:c_end] = argmax\n",
    "\n",
    "    # row/col corner\n",
    "    x = bands[-patch_size:, -patch_size:]\n",
    "    x = x[np.newaxis, :]\n",
    "    preds = model.predict(x)\n",
    "    argmax = np.argmax(preds[0], axis=-1)\n",
    "    labels[-patch_size:, -patch_size:] = argmax\n",
    "\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6362b81a-ef81-4128-b33d-9d32ae18510b",
   "metadata": {},
   "source": [
    "The following takes a decent amount of time as it's sliding a patch along the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0652fdfd-a406-4d28-b7fc-9d83e2801a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_labels = make_predictions(model, im_bands)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80bf54db-643e-489c-9d23-30725c29c169",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, (ax1, ax2) = plt.subplots(1, 2, figsize=(8, 8))\n",
    "ax1.set_title(\"True Labels\")\n",
    "ax1.imshow(tf.keras.utils.array_to_img(im_labels[..., np.newaxis]))\n",
    "ax1.axis(\"off\")\n",
    "ax2.set_title(\"Predicted Labels\")\n",
    "ax2.imshow(tf.keras.utils.array_to_img(predicted_labels[..., np.newaxis]))\n",
    "ax2.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd071987-d5ef-4c7c-b1f7-52aee43863ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = im_labels.reshape(-1)\n",
    "y_pred = predicted_labels.reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57860ffe-19ef-4bca-b5af-3e3ab2602b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "mtx = confusion_matrix(y_true, y_pred)\n",
    "_, ax = plt.subplots(figsize=(24, 24))\n",
    "sns.heatmap(mtx, annot=True, ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfff7a03-f5c1-47d0-985d-b31bd7b36ba9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
